Pytest results (Python 3.12) - 2026-02-19T16:22:48Z

============================= test session starts ==============================
platform linux -- Python 3.12.12, pytest-9.0.2, pluggy-1.6.0 -- /opt/hostedtoolcache/Python/3.12.12/x64/bin/python
cachedir: .pytest_cache
rootdir: /home/runner/work/gget/gget
configfile: pyproject.toml
plugins: zarr-3.1.5, fast-array-utils-1.3.1, cov-7.0.0
collecting ... collected 264 items

tests/test_8cube.py::TestSpecificity::test_specificity_basic PASSED      [  0%]
tests/test_8cube.py::TestPsiBlock::test_psi_block_basic PASSED           [  0%]
tests/test_8cube.py::TestGeneExpression::test_gene_expression_basic PASSED [  1%]
tests/test_archs4.py::TestArchs4::test_archs4_bad_ensembl PASSED         [  1%]
tests/test_archs4.py::TestArchs4::test_archs4_bad_gene PASSED            [  1%]
tests/test_archs4.py::TestArchs4::test_archs4_bad_gene_tissue PASSED     [  2%]
tests/test_archs4.py::TestArchs4::test_archs4_bad_species PASSED         [  2%]
tests/test_archs4.py::TestArchs4::test_archs4_bad_which PASSED           [  3%]
tests/test_archs4.py::TestArchs4::test_archs4_defaults PASSED            [  3%]
tests/test_archs4.py::TestArchs4::test_archs4_mouse_json_ensembl PASSED  [  3%]
tests/test_archs4.py::TestArchs4::test_archs4_tissue PASSED              [  4%]
tests/test_archs4.py::TestArchs4::test_archs4_tissue_ensembl PASSED      [  4%]
tests/test_archs4.py::TestArchs4::test_archs4_tissue_json PASSED         [  4%]
tests/test_archs4.py::TestArchs4::test_archs4_tissue_mouse PASSED        [  5%]
tests/test_bgee.py::TestBgee::test_bgee_expression PASSED                [  5%]
tests/test_bgee.py::TestBgee::test_bgee_expression_multiple PASSED       [  6%]
tests/test_bgee.py::TestBgee::test_bgee_orthologs PASSED                 [  6%]
tests/test_bgee.py::TestBgee::test_error_bgee_expression_no_exist PASSED [  6%]
tests/test_bgee.py::TestBgee::test_error_bgee_orthologs_no_exist PASSED  [  7%]
tests/test_bgee.py::TestBgee::test_error_bgee_unknown_type PASSED        [  7%]
tests/test_blast.py::TestBlast::test_blast_bad_db1 PASSED                [  7%]
tests/test_blast.py::TestBlast::test_blast_bad_db2 PASSED                [  8%]
tests/test_blast.py::TestBlast::test_blast_bad_fasta PASSED              [  8%]
tests/test_blast.py::TestBlast::test_blast_bad_program PASSED            [  9%]
tests/test_blast.py::TestBlast::test_blast_bad_seq PASSED                [  9%]
tests/test_blast.py::TestBlast::test_blast_db_missing PASSED             [  9%]
tests/test_blast.py::TestBlast::test_blast_nt PASSED                     [ 10%]
tests/test_blat.py::TestBlat::test_blat_aa PASSED                        [ 10%]
tests/test_blat.py::TestBlat::test_blat_aa_RNA PASSED                    [ 10%]
tests/test_blat.py::TestBlat::test_blat_aa_protein PASSED                [ 11%]
tests/test_blat.py::TestBlat::test_blat_bad_assembly PASSED              [ 11%]
tests/test_blat.py::TestBlat::test_blat_bad_fasta PASSED                 [ 12%]
tests/test_blat.py::TestBlat::test_blat_bad_fileformat PASSED            [ 12%]
tests/test_blat.py::TestBlat::test_blat_bad_seqtype PASSED               [ 12%]
tests/test_blat.py::TestBlat::test_blat_bad_txt PASSED                   [ 13%]
tests/test_blat.py::TestBlat::test_blat_nt PASSED                        [ 13%]
tests/test_blat.py::TestBlat::test_blat_nt_DNA PASSED                    [ 14%]
tests/test_blat.py::TestBlat::test_blat_nt_RNA PASSED                    [ 14%]
tests/test_blat.py::TestBlat::test_blat_nt_fasta PASSED                  [ 14%]
tests/test_blat.py::TestBlat::test_blat_nt_json PASSED                   [ 15%]
tests/test_blat.py::TestBlat::test_blat_nt_protein PASSED                [ 15%]
tests/test_blat.py::TestBlat::test_blat_nt_transDNA PASSED               [ 15%]
tests/test_blat.py::TestBlat::test_blat_nt_txt PASSED                    [ 16%]
tests/test_blat.py::TestBlat::test_blat_shortseq PASSED                  [ 16%]
tests/test_cbio.py::TestCbioSearch::test_cbio_search PASSED              [ 17%]
tests/test_cbio.py::TestCbio::test_cbio_download PASSED                  [ 17%]
tests/test_cbio.py::TestCbio::test_cbio_download_partially_existing_files PASSED [ 17%]
tests/test_cbio.py::TestCbio::test_error_cbio_download PASSED            [ 18%]
tests/test_cellxgene.py::TestCellxgene::test_cellxgene_adata PASSED      [ 18%]
tests/test_cellxgene.py::TestCellxgene::test_cellxgene_metadata PASSED   [ 18%]
tests/test_compile.py::TestCompilerWindows::test_compiler_windows PASSED [ 19%]
tests/test_cosmic.py::TestCosmicWorkflow::test_cosmic_defaults PASSED    [ 19%]
tests/test_diamond.py::TestDiamond::test_diamond_JSON_out PASSED         [ 20%]
tests/test_diamond.py::TestDiamond::test_diamond_both_files PASSED       [ 20%]
tests/test_diamond.py::TestDiamond::test_diamond_query_file PASSED       [ 20%]
tests/test_diamond.py::TestDiamond::test_diamond_ref_file PASSED         [ 21%]
tests/test_diamond.py::TestDiamond::test_diamond_seqs_multiple PASSED    [ 21%]
tests/test_diamond.py::TestDiamond::test_diamond_seqs_single PASSED      [ 21%]
tests/test_elm.py::TestELM::test_elm_uniprot_aminoacidseq PASSED         [ 22%]
tests/test_elm.py::TestELM::test_elm_uniprot_id_in_elm PASSED            [ 22%]
tests/test_elm.py::TestELM::test_elm_uniprot_id_new PASSED               [ 23%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_background PASSED       [ 23%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_background_ensembl PASSED [ 23%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_bad_background PASSED   [ 24%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_bad_background_list PASSED [ 24%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_bad_database_shortcut PASSED [ 25%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_bad_gene PASSED         [ 25%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_bad_species PASSED      [ 25%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_celltypes PASSED        [ 26%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_diseases_drugs PASSED   [ 26%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_ensembl_ids FAILED      [ 26%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_fish PASSED             [ 27%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_fly PASSED              [ 27%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_json PASSED             [ 28%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_kinase_interactions PASSED [ 28%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_mouse_is_human PASSED   [ 28%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_none PASSED             [ 29%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_ontology PASSED         [ 29%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_pathway PASSED          [ 29%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_plot PASSED             [ 30%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_transcription PASSED    [ 30%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_worm PASSED             [ 31%]
tests/test_enrichr.py::TestEnrichr::test_enrichr_yeast PASSED            [ 31%]
tests/test_gpt.py::TestGpt::test_gpt PASSED                              [ 31%]
tests/test_info.py::TestInfo::test_info_WB_transcript PASSED             [ 32%]
tests/test_info.py::TestInfo::test_info_exon PASSED                      [ 32%]
tests/test_info.py::TestInfo::test_info_gene PASSED                      [ 32%]
tests/test_info.py::TestInfo::test_info_gene_list_non_model PASSED       [ 33%]
tests/test_info.py::TestInfo::test_info_mix PASSED                       [ 33%]
tests/test_info.py::TestInfo::test_info_ncbifalse_uniprotfalse PASSED    [ 34%]
tests/test_info.py::TestInfo::test_info_ncbifalse_uniprottrue PASSED     [ 34%]
tests/test_info.py::TestInfo::test_info_ncbitrue_uniprotfalse PASSED     [ 34%]
tests/test_info.py::TestInfo::test_info_transcript PASSED                [ 35%]
tests/test_muscle.py::TestMuscle::test_muscle_nt PASSED                  [ 35%]
tests/test_muscle.py::TestMuscle::test_muscle_nt_txt PASSED              [ 35%]
tests/test_muscle.py::TestMuscleSuper::test_muscle_nt_super5 PASSED      [ 36%]
tests/test_muscle.py::TestMuscleAA::test_muscle_aa PASSED                [ 36%]
tests/test_muscle.py::TestMuscleSeqsInput::test_muscle_seqs_as_input PASSED [ 37%]
tests/test_muscle.py::TestMuscleAASuper::test_muscle_aa_super5 PASSED    [ 37%]
tests/test_muscle.py::TestMusclePrints::test_muscle_print_nt PASSED      [ 37%]
tests/test_mutate.py::TestMutate::test_ambiguous_mutation PASSED         [ 38%]
tests/test_mutate.py::TestMutate::test_index_error PASSED                [ 38%]
tests/test_mutate.py::TestMutate::test_intron_mutation_minus PASSED      [ 39%]
tests/test_mutate.py::TestMutate::test_intron_mutation_plus PASSED       [ 39%]
tests/test_mutate.py::TestMutate::test_inversion_with_overlaps PASSED    [ 39%]
tests/test_mutate.py::TestMutate::test_large_k PASSED                    [ 40%]
tests/test_mutate.py::TestMutate::test_list_of_mutations PASSED          [ 40%]
tests/test_mutate.py::TestMutate::test_multi_deletion PASSED             [ 40%]
tests/test_mutate.py::TestMutate::test_multi_deletion_with_right_repeats PASSED [ 41%]
tests/test_mutate.py::TestMutate::test_multi_delins PASSED               [ 41%]
tests/test_mutate.py::TestMutate::test_multi_delins_with_psuedo_left_repeats PASSED [ 42%]
tests/test_mutate.py::TestMutate::test_multi_delins_with_true_left_repeats PASSED [ 42%]
tests/test_mutate.py::TestMutate::test_multi_delins_with_true_right_repeats PASSED [ 42%]
tests/test_mutate.py::TestMutate::test_multi_dup PASSED                  [ 43%]
tests/test_mutate.py::TestMutate::test_multi_insertion PASSED            [ 43%]
tests/test_mutate.py::TestMutate::test_multi_insertion_with_left_repeats PASSED [ 43%]
tests/test_mutate.py::TestMutate::test_posttranslational_mutation PASSED [ 44%]
tests/test_mutate.py::TestMutate::test_single_deletion PASSED            [ 44%]
tests/test_mutate.py::TestMutate::test_single_deletion_with_left_repeats PASSED [ 45%]
tests/test_mutate.py::TestMutate::test_single_deletion_with_right_repeats PASSED [ 45%]
tests/test_mutate.py::TestMutate::test_single_delins PASSED              [ 45%]
tests/test_mutate.py::TestMutate::test_single_dup PASSED                 [ 46%]
tests/test_mutate.py::TestMutate::test_single_insertion PASSED           [ 46%]
tests/test_mutate.py::TestMutate::test_single_substitution PASSED        [ 46%]
tests/test_mutate.py::TestMutate::test_single_substitution_near_left_end PASSED [ 47%]
tests/test_mutate.py::TestMutate::test_single_substitution_near_right_end PASSED [ 47%]
tests/test_mutate.py::TestMutate::test_uncertain_mutation PASSED         [ 48%]
tests/test_mutate.py::test_csv_of_mutations PASSED                       [ 48%]
tests/test_mutate.py::test_mismatch_error PASSED                         [ 48%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_bad_limit PASSED [ 49%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_bad_resource PASSED [ 49%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_diseases_filter PASSED [ 50%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_drugs_invalid_filter PASSED [ 50%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_nonexistent_id PASSED [ 50%]
tests/test_opentargets.py::TestOpenTargets::test_error_opentargets_tractability_limit PASSED [ 51%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets PASSED      [ 51%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_depmap PASSED [ 51%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_depmap_filter PASSED [ 52%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_drugs PASSED [ 52%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_drugs_no_limit PASSED [ 53%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_expression_no_limit PASSED [ 53%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_interactions_no_limit PASSED [ 53%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_interactions_simple_filter PASSED [ 54%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_no_limit PASSED [ 54%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_no_limit_accurate_coverage PASSED [ 54%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_pharmacogenetics_filter_or PASSED [ 55%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_pharmacogenetics_no_limit PASSED [ 55%]
tests/test_opentargets.py::TestOpenTargets::test_opentargets_tractability PASSED [ 56%]
tests/test_pdb.py::TestPDB::test_pdb_assembly PASSED                     [ 56%]
tests/test_pdb.py::TestPDB::test_pdb_pdb PASSED                          [ 56%]
tests/test_ref.py::TestRef::test_ref PASSED                              [ 57%]
tests/test_ref.py::TestRef::test_ref_bad_rel PASSED                      [ 57%]
tests/test_ref.py::TestRef::test_ref_bad_species PASSED                  [ 57%]
tests/test_ref.py::TestRef::test_ref_bad_which PASSED                    [ 58%]
tests/test_ref.py::TestRef::test_ref_ftp PASSED                          [ 58%]
tests/test_ref.py::TestRef::test_ref_list PASSED                         [ 59%]
tests/test_ref.py::TestRef::test_ref_plant PASSED                        [ 59%]
tests/test_ref.py::TestRef::test_ref_rel PASSED                          [ 59%]
tests/test_ref.py::TestRef::test_ref_rel_ftp PASSED                      [ 60%]
tests/test_ref.py::TestRef::test_ref_rel_ftp_octopus PASSED              [ 60%]
tests/test_ref.py::TestRef::test_ref_rel_protist PASSED                  [ 60%]
tests/test_ref.py::TestRef::test_ref_which PASSED                        [ 61%]
tests/test_ref.py::TestRef::test_ref_which_plant PASSED                  [ 61%]
tests/test_search.py::TestSearch::test_search_db PASSED                  [ 62%]
tests/test_search.py::TestSearch::test_search_gene_bad_andor PASSED      [ 62%]
tests/test_search.py::TestSearch::test_search_gene_bad_species PASSED    [ 62%]
tests/test_search.py::TestSearch::test_search_gene_one_sw PASSED         [ 63%]
tests/test_search.py::TestSearch::test_search_gene_one_sw_json PASSED    [ 63%]
tests/test_search.py::TestSearch::test_search_gene_one_sw_limit PASSED   [ 64%]
tests/test_search.py::TestSearch::test_search_gene_two_sw_and PASSED     [ 64%]
tests/test_search.py::TestSearch::test_search_gene_two_sw_limit PASSED   [ 64%]
tests/test_search.py::TestSearch::test_search_gene_two_sw_or PASSED      [ 65%]
tests/test_search.py::TestSearch::test_search_octopus PASSED             [ 65%]
tests/test_search.py::TestSearch::test_search_plant PASSED               [ 65%]
tests/test_search.py::TestSearch::test_search_plant_db PASSED            [ 66%]
tests/test_search.py::TestSearch::test_search_release PASSED             [ 66%]
tests/test_search.py::TestSearch::test_search_transcript_bad_andor PASSED [ 67%]
tests/test_search.py::TestSearch::test_search_transcript_bad_species PASSED [ 67%]
tests/test_search.py::TestSearch::test_search_transcript_one_sw PASSED   [ 67%]
tests/test_search.py::TestSearch::test_search_transcript_two_sw_and PASSED [ 68%]
tests/test_search.py::TestSearch::test_search_transcript_two_sw_or PASSED [ 68%]
tests/test_seq.py::TestSeq::test_seq_gene PASSED                         [ 68%]
tests/test_seq.py::TestSeq::test_seq_gene_iso PASSED                     [ 69%]
tests/test_seq.py::TestSeq::test_seq_gene_transcript_iso PASSED          [ 69%]
tests/test_seq.py::TestSeq::test_seq_missing_uniprot_gene_name PASSED    [ 70%]
tests/test_seq.py::TestSeq::test_seq_transcript PASSED                   [ 70%]
tests/test_seq.py::TestSeq::test_seq_transcript_gene PASSED              [ 70%]
tests/test_seq.py::TestSeq::test_seq_transcript_gene_WB PASSED           [ 71%]
tests/test_seq.py::TestSeq::test_seq_transcript_gene_iso PASSED          [ 71%]
tests/test_seq.py::TestSeq::test_seq_transcript_transcript_WB PASSED     [ 71%]
tests/test_seq.py::TestSeq::test_seq_transcript_transcript_iso PASSED    [ 72%]
tests/test_utils.py::TestUtils::test_aa_colors PASSED                    [ 72%]
tests/test_utils.py::TestUtils::test_find_latest_ens_rel PASSED          [ 73%]
tests/test_utils.py::TestUtils::test_get_uniprot_info_gene PASSED        [ 73%]
tests/test_utils.py::TestUtils::test_get_uniprot_info_transcript PASSED  [ 73%]
tests/test_utils.py::TestUtils::test_get_uniprot_seqs PASSED             [ 74%]
tests/test_utils.py::TestUtils::test_n_colors PASSED                     [ 74%]
tests/test_utils.py::TestUtils::test_read_fasta PASSED                   [ 75%]
tests/test_utils.py::TestUtils::test_ref_iv_species_options PASSED       [ 75%]
tests/test_utils.py::TestUtils::test_ref_species_options PASSED          [ 75%]
tests/test_utils.py::TestUtils::test_ref_species_options_bad_type PASSED [ 76%]
tests/test_utils.py::TestUtils::test_rest_query PASSED                   [ 76%]
tests/test_utils.py::TestUtils::test_rest_query_bad_type PASSED          [ 76%]
tests/test_utils.py::TestUtils::test_search_iv_species_options PASSED    [ 77%]
tests/test_utils.py::TestUtils::test_search_species_options PASSED       [ 77%]
tests/test_utils.py::TestUtils::test_search_species_options_bad_type PASSED [ 78%]
tests/test_virus.py::TestVirus::test_batch_accessions_for_url PASSED     [ 78%]
tests/test_virus.py::TestVirus::test_calculate_max_accessions_per_batch PASSED [ 78%]
tests/test_virus.py::TestVirus::test_datasets_cli_version_output PASSED  [ 79%]
tests/test_virus.py::TestVirus::test_get_datasets_path_returns_valid_path PASSED [ 79%]
tests/test_virus.py::TestVirus::test_get_datasets_path_uses_bundled_binary PASSED [ 79%]
tests/test_virus.py::TestVirus::test_parse_accession_input_empty_file_raises_error PASSED [ 80%]
tests/test_virus.py::TestVirus::test_parse_accession_input_from_file PASSED [ 80%]
tests/test_virus.py::TestVirus::test_parse_accession_input_nonexistent_file_raises_error PASSED [ 81%]
tests/test_virus.py::TestVirus::test_parse_accession_input_single PASSED [ 81%]
tests/test_virus.py::TestVirus::test_parse_accession_input_space_separated PASSED [ 81%]
tests/test_virus.py::TestVirus::test_retry_helper_custom_retryable_exceptions PASSED [ 82%]
tests/test_virus.py::TestVirus::test_retry_helper_exponential_backoff_timing PASSED [ 82%]
tests/test_virus.py::TestVirus::test_retry_helper_failed_commands_tracking PASSED [ 82%]
tests/test_virus.py::TestVirus::test_retry_helper_non_retryable_exception PASSED [ 83%]
tests/test_virus.py::TestVirus::test_retry_helper_success_after_retry PASSED [ 83%]
tests/test_virus.py::TestVirus::test_retry_helper_successful_operation PASSED [ 84%]
tests/test_virus.py::TestVirus::test_virus_completeness_filter_verification PASSED [ 84%]
tests/test_virus.py::TestVirus::test_virus_empty_virus_name PASSED       [ 84%]
tests/test_virus.py::TestVirus::test_virus_host_filter_verification PASSED [ 85%]
tests/test_virus.py::TestVirus::test_virus_integer_virus_id PASSED       [ 85%]
tests/test_virus.py::TestVirus::test_virus_invalid_annotated_type PASSED [ 85%]
tests/test_virus.py::TestVirus::test_virus_invalid_completeness PASSED   [ 86%]
tests/test_virus.py::TestVirus::test_virus_invalid_genbank_batch_size_negative PASSED [ 86%]
tests/test_virus.py::TestVirus::test_virus_invalid_genbank_batch_size_type PASSED [ 87%]
tests/test_virus.py::TestVirus::test_virus_invalid_genbank_batch_size_zero PASSED [ 87%]
tests/test_virus.py::TestVirus::test_virus_invalid_genbank_metadata_type PASSED [ 87%]
tests/test_virus.py::TestVirus::test_virus_invalid_is_accession_type PASSED [ 88%]
tests/test_virus.py::TestVirus::test_virus_invalid_keep_temp_type PASSED [ 88%]
tests/test_virus.py::TestVirus::test_virus_invalid_lab_passaged_type PASSED [ 89%]
tests/test_virus.py::TestVirus::test_virus_invalid_proteins_complete_type PASSED [ 89%]
tests/test_virus.py::TestVirus::test_virus_invalid_refseq_only_type PASSED [ 89%]
tests/test_virus.py::TestVirus::test_virus_metadata_schema_validation PASSED [ 90%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_collection_date PASSED [ 90%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_gene_count PASSED [ 90%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_peptide_count PASSED [ 91%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_protein_count PASSED [ 91%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_release_date PASSED [ 92%]
tests/test_virus.py::TestVirus::test_virus_min_greater_than_max_seq_length PASSED [ 92%]
tests/test_virus.py::TestVirus::test_virus_multi_accession_file_input PASSED [ 92%]
tests/test_virus.py::TestVirus::test_virus_multi_accession_space_separated PASSED [ 93%]
tests/test_virus.py::TestVirus::test_virus_multiple_filters_relationship_check PASSED [ 93%]
tests/test_virus.py::TestVirus::test_virus_none_virus_name PASSED        [ 93%]
tests/test_virus.py::TestVirus::test_virus_relationship_check_counts_match PASSED [ 94%]
tests/test_virus.py::TestVirus::test_virus_release_date_filter_verification PASSED [ 94%]
tests/test_virus.py::TestVirus::test_virus_specific_accession_file_creation PASSED [ 95%]
tests/test_virus.py::TestVirus::test_virus_with_annotated_filter PASSED  [ 95%]
tests/test_virus.py::TestVirus::test_virus_with_collection_date_filters PASSED [ 95%]
tests/test_virus.py::TestVirus::test_virus_with_completeness_filter PASSED [ 96%]
tests/test_virus.py::TestVirus::test_virus_with_genbank_metadata_retrieval PASSED [ 96%]
tests/test_virus.py::TestVirus::test_virus_with_geographic_location_filter PASSED [ 96%]
tests/test_virus.py::TestVirus::test_virus_with_has_proteins_filter PASSED [ 97%]
tests/test_virus.py::TestVirus::test_virus_with_host_filter PASSED       [ 97%]
tests/test_virus.py::TestVirus::test_virus_with_lab_passaged_filter PASSED [ 98%]
tests/test_virus.py::TestVirus::test_virus_with_length_filters FAILED    [ 98%]
tests/test_virus.py::TestVirus::test_virus_with_max_ambiguous_chars_filter PASSED [ 98%]
tests/test_virus.py::TestVirus::test_virus_with_multiple_filters PASSED  [ 99%]
tests/test_virus.py::TestVirus::test_virus_with_protein_count_filters PASSED [ 99%]
tests/test_virus.py::TestVirus::test_virus_with_refseq_filter PASSED     [100%]

=================================== FAILURES ===================================
_____________________ TestEnrichr.test_enrichr_ensembl_ids _____________________

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
method = 'POST', url = '/lookup/id/'
body = b'{"ids": ["ENSG00000106443", "ENSG00000102317", "ENSG00000188895", "ENSG00000135365"], "expand": true}'
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Type': 'application/json', 'Content-Length': '101'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/lookup/id/', query=None, fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connectionpool.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
conn = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>
method = 'POST', url = '/lookup/id/'
body = b'{"ids": ["ENSG00000106443", "ENSG00000102317", "ENSG00000188895", "ENSG00000135365"], "expand": true}'
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Type': 'application/json', 'Content-Length': '101'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
timeout = Timeout(connect=None, read=None, total=None), chunked = False
response_conn = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>
preload_content = False, decode_content = False, enforce_content_length = True

    def _make_request(
        self,
        conn: BaseHTTPConnection,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | None = None,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        chunked: bool = False,
        response_conn: BaseHTTPConnection | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        enforce_content_length: bool = True,
    ) -> BaseHTTPResponse:
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param response_conn:
            Set this to ``None`` if you will handle releasing the connection or
            set the connection to have the response release it.
    
        :param preload_content:
          If True, the response's body will be preloaded during construction.
    
        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param enforce_content_length:
            Enforce content length checking. Body returned by server must match
            value of Content-Length header, if present. Otherwise, raise error.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)
    
        try:
            # Trigger any extra validation we need to do.
            try:
                self._validate_conn(conn)
            except (SocketTimeout, BaseSSLError) as e:
                self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
                raise
    
        # _validate_conn() starts the connection to an HTTPS proxy
        # so we need to wrap errors with 'ProxyError' here too.
        except (
            OSError,
            NewConnectionError,
            TimeoutError,
            BaseSSLError,
            CertificateError,
            SSLError,
        ) as e:
            new_e: Exception = e
            if isinstance(e, (BaseSSLError, CertificateError)):
                new_e = SSLError(e)
            # If the connection didn't successfully connect to it's proxy
            # then there
            if isinstance(
                new_e, (OSError, NewConnectionError, TimeoutError, SSLError)
            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):
                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)
            raise new_e
    
        # conn.request() calls http.client.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        try:
            conn.request(
                method,
                url,
                body=body,
                headers=headers,
                chunked=chunked,
                preload_content=preload_content,
                decode_content=decode_content,
                enforce_content_length=enforce_content_length,
            )
    
        # We are swallowing BrokenPipeError (errno.EPIPE) since the server is
        # legitimately able to close the connection after sending a valid response.
        # With this behaviour, the received response is still readable.
        except BrokenPipeError:
            pass
        except OSError as e:
            # MacOS/Linux
            # EPROTOTYPE and ECONNRESET are needed on macOS
            # https://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/
            # Condition changed later to emit ECONNRESET instead of only EPROTOTYPE.
            if e.errno != errno.EPROTOTYPE and e.errno != errno.ECONNRESET:
                raise
    
        # Reset the timeout for the recv() on the socket
        read_timeout = timeout_obj.read_timeout
    
        if not conn.is_closed:
            # In Python 3 socket.py will catch EAGAIN and return None when you
            # try and read into the file pointer created by http.client, which
            # instead raises a BadStatusLine exception. Instead of catching
            # the exception and assuming all BadStatusLine exceptions are read
            # timeouts, check for a zero timeout before making the request.
            if read_timeout == 0:
                raise ReadTimeoutError(
                    self, url, f"Read timed out. (read timeout={read_timeout})"
                )
            conn.timeout = read_timeout
    
        # Receive the response from the server
        try:
>           response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connectionpool.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>

    def getresponse(  # type: ignore[override]
        self,
    ) -> HTTPResponse:
        """
        Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an instance of HTTPResponse or of whatever object is returned by the response_class variable.
    
        If a request has not been sent or if a previous response has not be handled, ResponseNotReady is raised. If the HTTP response indicates that the connection should be closed, then it will be closed before the response is returned. When the connection is closed, the underlying socket is closed.
        """
        # Raise the same error as http.client.HTTPConnection
        if self._response_options is None:
            raise ResponseNotReady()
    
        # Reset this attribute for being used again.
        resp_options = self._response_options
        self._response_options = None
    
        # Since the connection's timeout value may have been updated
        # we need to set the timeout on the socket.
        self.sock.settimeout(self.timeout)
    
        # This is needed here to avoid circular import errors
        from .response import HTTPResponse
    
        # Save a reference to the shutdown function before ownership is passed
        # to httplib_response
        # TODO should we implement it everywhere?
        _shutdown = getattr(self.sock, "shutdown", None)
    
        # Get the response from http.client.HTTPConnection
>       httplib_response = super().getresponse()
                           ^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connection.py:571: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>

    def getresponse(self):
        """Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.
    
        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        """
    
        # if a prior response has been completed, then forget about it.
        if self.__response and self.__response.isclosed():
            self.__response = None
    
        # if a prior response exists, then it must be completed (otherwise, we
        # cannot read this response's header to determine the connection-close
        # behavior)
        #
        # note: if a prior response existed, but was connection-close, then the
        # socket and response were made independent of this HTTPConnection
        # object since a new request requires that we open a whole new
        # connection
        #
        # this means the prior response had one of two states:
        #   1) will_close: this connection was reset and the prior socket and
        #                  response operate independently
        #   2) persistent: the response was retained and we await its
        #                  isclosed() status to become true.
        #
        if self.__state != _CS_REQ_SENT or self.__response:
            raise ResponseNotReady(self.__state)
    
        if self.debuglevel > 0:
            response = self.response_class(self.sock, self.debuglevel,
                                           method=self._method)
        else:
            response = self.response_class(self.sock, method=self._method)
    
        try:
            try:
>               response.begin()

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:1430: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <http.client.HTTPResponse object at 0x7f6afc90ba60>

    def begin(self):
        if self.headers is not None:
            # we've already started reading the response
            return
    
        # read until we get a non-100 response
        while True:
>           version, status, reason = self._read_status()
                                      ^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <http.client.HTTPResponse object at 0x7f6afc90ba60>

    def _read_status(self):
>       line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <socket.SocketIO object at 0x7f6ad8bef220>
b = <memory at 0x7f6ae88dc7c0>

    def readinto(self, b):
        """Read up to len(b) bytes into the writable buffer *b* and return
        the number of bytes read.  If the socket is non-blocking and no bytes
        are available, None is returned.
    
        If *b* is non-empty, a 0 return value indicates that the connection
        was shutdown at the other end.
        """
        self._checkClosed()
        self._checkReadable()
        if self._timeout_occurred:
            raise OSError("cannot read from timed out object")
        while True:
            try:
>               return self._sock.recv_into(b)
                       ^^^^^^^^^^^^^^^^^^^^^^^
E               ConnectionResetError: [Errno 104] Connection reset by peer

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/socket.py:720: ConnectionResetError

During handling of the above exception, another exception occurred:

self = <requests.adapters.HTTPAdapter object at 0x7f6ae85b71a0>
request = <PreparedRequest [POST]>, stream = False
timeout = Timeout(connect=None, read=None, total=None), verify = True
cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
>           resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/adapters.py:644: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
method = 'POST', url = '/lookup/id/'
body = b'{"ids": ["ENSG00000106443", "ENSG00000102317", "ENSG00000188895", "ENSG00000135365"], "expand": true}'
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Type': 'application/json', 'Content-Length': '101'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/lookup/id/', query=None, fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
            response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )
    
            # Everything went great!
            clean_exit = True
    
        except EmptyPoolError:
            # Didn't get a connection from the pool, no need to clean up
            clean_exit = True
            release_this_conn = False
            raise
    
        except (
            TimeoutError,
            HTTPException,
            OSError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
            ProxyError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False
            new_e: Exception = e
            if isinstance(e, (BaseSSLError, CertificateError)):
                new_e = SSLError(e)
            if isinstance(
                new_e,
                (
                    OSError,
                    NewConnectionError,
                    TimeoutError,
                    SSLError,
                    HTTPException,
                ),
            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):
                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)
            elif isinstance(new_e, (OSError, HTTPException)):
                new_e = ProtocolError("Connection aborted.", new_e)
    
>           retries = retries.increment(
                method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]
            )

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connectionpool.py:841: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Retry(total=0, connect=None, read=False, redirect=None, status=None)
method = 'POST', url = '/lookup/id/', response = None
error = ProtocolError('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
_pool = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
_stacktrace = <traceback object at 0x7f6ae88b4280>

    def increment(
        self,
        method: str | None = None,
        url: str | None = None,
        response: BaseHTTPResponse | None = None,
        error: Exception | None = None,
        _pool: ConnectionPool | None = None,
        _stacktrace: TracebackType | None = None,
    ) -> Self:
        """Return a new Retry object with incremented retry counters.
    
        :param response: A response object, or None, if the server did not
            return a response.
        :type response: :class:`~urllib3.response.BaseHTTPResponse`
        :param Exception error: An error encountered during the request, or
            None if the response was received successfully.
    
        :return: A new ``Retry`` object.
        """
        if self.total is False and error:
            # Disabled, indicate to re-raise the error.
            raise reraise(type(error), error, _stacktrace)
    
        total = self.total
        if total is not None:
            total -= 1
    
        connect = self.connect
        read = self.read
        redirect = self.redirect
        status_count = self.status
        other = self.other
        cause = "unknown"
        status = None
        redirect_location = None
    
        if error and self._is_connection_error(error):
            # Connect retry?
            if connect is False:
                raise reraise(type(error), error, _stacktrace)
            elif connect is not None:
                connect -= 1
    
        elif error and self._is_read_error(error):
            # Read retry?
            if read is False or method is None or not self._is_method_retryable(method):
>               raise reraise(type(error), error, _stacktrace)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/util/retry.py:490: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

tp = <class 'urllib3.exceptions.ProtocolError'>, value = None, tb = None

    def reraise(
        tp: type[BaseException] | None,
        value: BaseException,
        tb: TracebackType | None = None,
    ) -> typing.NoReturn:
        try:
            if value.__traceback__ is not tb:
>               raise value.with_traceback(tb)

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/util/util.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
method = 'POST', url = '/lookup/id/'
body = b'{"ids": ["ENSG00000106443", "ENSG00000102317", "ENSG00000188895", "ENSG00000135365"], "expand": true}'
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Type': 'application/json', 'Content-Length': '101'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
redirect = False, assert_same_host = False
timeout = Timeout(connect=None, read=None, total=None), pool_timeout = None
release_conn = False, chunked = False, body_pos = None, preload_content = False
decode_content = False, response_kw = {}
parsed_url = Url(scheme=None, auth=None, host=None, port=None, path='/lookup/id/', query=None, fragment=None)
destination_scheme = None, conn = None, release_this_conn = True
http_tunnel_required = False, err = None, clean_exit = False

    def urlopen(  # type: ignore[override]
        self,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | bool | int | None = None,
        redirect: bool = True,
        assert_same_host: bool = True,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        pool_timeout: int | None = None,
        release_conn: bool | None = None,
        chunked: bool = False,
        body_pos: _TYPE_BODY_POSITION | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        **response_kw: typing.Any,
    ) -> BaseHTTPResponse:
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.
    
        .. note::
    
           More commonly, it's appropriate to use a convenience method
           such as :meth:`request`.
    
        .. note::
    
           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.
    
        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.
    
        :param bool preload_content:
            If True, the response's body will be preloaded into memory.
    
        :param bool decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of ``preload_content``
            which defaults to ``True``.
    
        :param bool chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.
        """
        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme
    
        if headers is None:
            headers = self.headers
    
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)
    
        if release_conn is None:
            release_conn = preload_content
    
        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)
    
        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = to_str(_encode_target(url))
        else:
            url = to_str(parsed_url.url)
    
        conn = None
    
        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn
    
        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )
    
        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()  # type: ignore[attr-defined]
            headers.update(self.proxy_headers)  # type: ignore[union-attr]
    
        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None
    
        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False
    
        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)
    
        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)
    
            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]
    
            # Is this a closed/new connection that requires CONNECT tunnelling?
            if self.proxy is not None and http_tunnel_required and conn.is_closed:
                try:
                    self._prepare_proxy(conn)
                except (BaseSSLError, OSError, SocketTimeout) as e:
                    self._raise_timeout(
                        err=e, url=self.proxy.url, timeout_value=conn.timeout
                    )
                    raise
    
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None
    
            # Make the request on the HTTPConnection object
>           response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
                retries=retries,
                response_conn=response_conn,
                preload_content=preload_content,
                decode_content=decode_content,
                **response_kw,
            )

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connectionpool.py:787: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <urllib3.connectionpool.HTTPConnectionPool object at 0x7f6ae85b7e00>
conn = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>
method = 'POST', url = '/lookup/id/'
body = b'{"ids": ["ENSG00000106443", "ENSG00000102317", "ENSG00000188895", "ENSG00000135365"], "expand": true}'
headers = {'User-Agent': 'python-requests/2.32.5', 'Accept-Encoding': 'gzip, deflate', 'Accept': '*/*', 'Connection': 'keep-alive', 'Content-Type': 'application/json', 'Content-Length': '101'}
retries = Retry(total=0, connect=None, read=False, redirect=None, status=None)
timeout = Timeout(connect=None, read=None, total=None), chunked = False
response_conn = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>
preload_content = False, decode_content = False, enforce_content_length = True

    def _make_request(
        self,
        conn: BaseHTTPConnection,
        method: str,
        url: str,
        body: _TYPE_BODY | None = None,
        headers: typing.Mapping[str, str] | None = None,
        retries: Retry | None = None,
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        chunked: bool = False,
        response_conn: BaseHTTPConnection | None = None,
        preload_content: bool = True,
        decode_content: bool = True,
        enforce_content_length: bool = True,
    ) -> BaseHTTPResponse:
        """
        Perform a request on a given urllib connection object taken from our
        pool.
    
        :param conn:
            a connection from one of our connection pools
    
        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)
    
        :param url:
            The URL to perform the request on.
    
        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.
    
        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.
    
        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.
    
            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.
    
            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.
    
        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.
    
        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.
    
        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.
    
        :param response_conn:
            Set this to ``None`` if you will handle releasing the connection or
            set the connection to have the response release it.
    
        :param preload_content:
          If True, the response's body will be preloaded during construction.
    
        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
    
        :param enforce_content_length:
            Enforce content length checking. Body returned by server must match
            value of Content-Length header, if present. Otherwise, raise error.
        """
        self.num_requests += 1
    
        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)
    
        try:
            # Trigger any extra validation we need to do.
            try:
                self._validate_conn(conn)
            except (SocketTimeout, BaseSSLError) as e:
                self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
                raise
    
        # _validate_conn() starts the connection to an HTTPS proxy
        # so we need to wrap errors with 'ProxyError' here too.
        except (
            OSError,
            NewConnectionError,
            TimeoutError,
            BaseSSLError,
            CertificateError,
            SSLError,
        ) as e:
            new_e: Exception = e
            if isinstance(e, (BaseSSLError, CertificateError)):
                new_e = SSLError(e)
            # If the connection didn't successfully connect to it's proxy
            # then there
            if isinstance(
                new_e, (OSError, NewConnectionError, TimeoutError, SSLError)
            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):
                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)
            raise new_e
    
        # conn.request() calls http.client.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        try:
            conn.request(
                method,
                url,
                body=body,
                headers=headers,
                chunked=chunked,
                preload_content=preload_content,
                decode_content=decode_content,
                enforce_content_length=enforce_content_length,
            )
    
        # We are swallowing BrokenPipeError (errno.EPIPE) since the server is
        # legitimately able to close the connection after sending a valid response.
        # With this behaviour, the received response is still readable.
        except BrokenPipeError:
            pass
        except OSError as e:
            # MacOS/Linux
            # EPROTOTYPE and ECONNRESET are needed on macOS
            # https://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/
            # Condition changed later to emit ECONNRESET instead of only EPROTOTYPE.
            if e.errno != errno.EPROTOTYPE and e.errno != errno.ECONNRESET:
                raise
    
        # Reset the timeout for the recv() on the socket
        read_timeout = timeout_obj.read_timeout
    
        if not conn.is_closed:
            # In Python 3 socket.py will catch EAGAIN and return None when you
            # try and read into the file pointer created by http.client, which
            # instead raises a BadStatusLine exception. Instead of catching
            # the exception and assuming all BadStatusLine exceptions are read
            # timeouts, check for a zero timeout before making the request.
            if read_timeout == 0:
                raise ReadTimeoutError(
                    self, url, f"Read timed out. (read timeout={read_timeout})"
                )
            conn.timeout = read_timeout
    
        # Receive the response from the server
        try:
>           response = conn.getresponse()
                       ^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connectionpool.py:534: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>

    def getresponse(  # type: ignore[override]
        self,
    ) -> HTTPResponse:
        """
        Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an instance of HTTPResponse or of whatever object is returned by the response_class variable.
    
        If a request has not been sent or if a previous response has not be handled, ResponseNotReady is raised. If the HTTP response indicates that the connection should be closed, then it will be closed before the response is returned. When the connection is closed, the underlying socket is closed.
        """
        # Raise the same error as http.client.HTTPConnection
        if self._response_options is None:
            raise ResponseNotReady()
    
        # Reset this attribute for being used again.
        resp_options = self._response_options
        self._response_options = None
    
        # Since the connection's timeout value may have been updated
        # we need to set the timeout on the socket.
        self.sock.settimeout(self.timeout)
    
        # This is needed here to avoid circular import errors
        from .response import HTTPResponse
    
        # Save a reference to the shutdown function before ownership is passed
        # to httplib_response
        # TODO should we implement it everywhere?
        _shutdown = getattr(self.sock, "shutdown", None)
    
        # Get the response from http.client.HTTPConnection
>       httplib_response = super().getresponse()
                           ^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/urllib3/connection.py:571: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <HTTPConnection(host='rest.ensembl.org', port=80) at 0x7f6ad8befd70>

    def getresponse(self):
        """Get the response from the server.
    
        If the HTTPConnection is in the correct state, returns an
        instance of HTTPResponse or of whatever object is returned by
        the response_class variable.
    
        If a request has not been sent or if a previous response has
        not be handled, ResponseNotReady is raised.  If the HTTP
        response indicates that the connection should be closed, then
        it will be closed before the response is returned.  When the
        connection is closed, the underlying socket is closed.
        """
    
        # if a prior response has been completed, then forget about it.
        if self.__response and self.__response.isclosed():
            self.__response = None
    
        # if a prior response exists, then it must be completed (otherwise, we
        # cannot read this response's header to determine the connection-close
        # behavior)
        #
        # note: if a prior response existed, but was connection-close, then the
        # socket and response were made independent of this HTTPConnection
        # object since a new request requires that we open a whole new
        # connection
        #
        # this means the prior response had one of two states:
        #   1) will_close: this connection was reset and the prior socket and
        #                  response operate independently
        #   2) persistent: the response was retained and we await its
        #                  isclosed() status to become true.
        #
        if self.__state != _CS_REQ_SENT or self.__response:
            raise ResponseNotReady(self.__state)
    
        if self.debuglevel > 0:
            response = self.response_class(self.sock, self.debuglevel,
                                           method=self._method)
        else:
            response = self.response_class(self.sock, method=self._method)
    
        try:
            try:
>               response.begin()

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:1430: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <http.client.HTTPResponse object at 0x7f6afc90ba60>

    def begin(self):
        if self.headers is not None:
            # we've already started reading the response
            return
    
        # read until we get a non-100 response
        while True:
>           version, status, reason = self._read_status()
                                      ^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:331: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <http.client.HTTPResponse object at 0x7f6afc90ba60>

    def _read_status(self):
>       line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/http/client.py:292: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <socket.SocketIO object at 0x7f6ad8bef220>
b = <memory at 0x7f6ae88dc7c0>

    def readinto(self, b):
        """Read up to len(b) bytes into the writable buffer *b* and return
        the number of bytes read.  If the socket is non-blocking and no bytes
        are available, None is returned.
    
        If *b* is non-empty, a 0 return value indicates that the connection
        was shutdown at the other end.
        """
        self._checkClosed()
        self._checkReadable()
        if self._timeout_occurred:
            raise OSError("cannot read from timed out object")
        while True:
            try:
>               return self._sock.recv_into(b)
                       ^^^^^^^^^^^^^^^^^^^^^^^
E               urllib3.exceptions.ProtocolError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/socket.py:720: ProtocolError

During handling of the above exception, another exception occurred:

self = <tests.test_enrichr.TestEnrichr testMethod=test_enrichr_ensembl_ids>

    def assert_equal(self: unittest.TestCase):
        test = name
        expected_result = td[test]["expected_result"]
>       result_to_test = do_call(func, td[test]["args"])
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

tests/from_json.py:65: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

func = <function enrichr at 0x7f6aff296980>
args = {'database': 'ontology', 'ensembl': True, 'genes': ['ENSG00000106443.2', 'ENSG00000102317', 'ENSG00000188895.4', 'ENSG00000135365']}

    def do_call(func, args):
        if isinstance(args, dict):
>           return func(**args)
                   ^^^^^^^^^^^^

tests/from_json.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

genes = ['ENSG00000106443.2', 'ENSG00000102317', 'ENSG00000188895.4', 'ENSG00000135365']
database = 'GO_Biological_Process_2021', species = 'human'
background_list = None, background = False, ensembl = True, ensembl_bkg = False
plot = False, figsize = (10, 10), ax = None, kegg_out = None, kegg_rank = 1
json = False, save = False, verbose = True

    def enrichr(
        genes,
        database,
        species="human",
        background_list=None,
        background=False,
        ensembl=False,
        ensembl_bkg=False,
        plot=False,
        figsize=(10, 10),
        ax=None,
        kegg_out=None,
        kegg_rank=1,
        json=False,
        save=False,
        verbose=True,
    ):
        """
        Perform an enrichment analysis on a list of genes using Enrichr (https://maayanlab.cloud/Enrichr/).
    
        Args:
        - genes             List of Entrez gene symbols to perform enrichment analysis on, passed as a list of strings, e.g. ['PHF14', 'RBM3', 'MSL1', 'PHF21A'].
                            Set 'ensembl = True' to input a list of Ensembl gene IDs, e.g. ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895'].
        - database          Database to use as reference for the enrichment analysis.
                            Supported shortcuts (and their default database), ONLY SUPPORTED FOR HUMAN/MOUSE SPECIES (other species must specify the full database name):
                            'pathway' (KEGG_2021_Human)
                            'transcription' (ChEA_2016)
                            'ontology' (GO_Biological_Process_2021)
                            'diseases_drugs' (GWAS_Catalog_2019)
                            'celltypes' (PanglaoDB_Augmented_2021)
                            'kinase_interactions' (KEA_2015)
                            or any database listed under Gene-set Library at: https://maayanlab.cloud/Enrichr/#libraries or the species-specific libraries listed below
        - species           Enrichr species database to query. Options:
                            'human' (default) [H. sapiens] - https://maayanlab.cloud/Enrichr/#libraries
                            'mouse' [M. musculus] - equivalent to 'human'
                            'fly' [D. melanogaster] - https://maayanlab.cloud/FlyEnrichr/#stats
                            'yeast' [S. cerevisiae] - https://maayanlab.cloud/YeastEnrichr/#stats
                            'worm' [C. elegans] - https://maayanlab.cloud/WormEnrichr/#stats
                            'fish' [D. rerio] - https://maayanlab.cloud/FishEnrichr/#stats
        - background_list   List of gene names/Ensembl IDs to be used as background genes. ONLY SUPPORTED FOR HUMAN/MOUSE SPECIES (Default: None)
        - background        If True, use set of > 20,000 default background genes listed here: https://github.com/pachterlab/gget/blob/main/gget/constants/enrichr_bkg_genes.txt.
                            ONLY SUPPORTED FOR HUMAN/MOUSE SPECIES (Default: False)
        - ensembl           Define as 'True' if 'genes' is a list of Ensembl gene IDs. (Default: False)
        - ensembl_bkg       Define as 'True' if 'background_list' is a list of Ensembl gene IDs. (Default: False)
        - plot              True/False whether to provide a graphical overview of the first 15 results. (Default: False)
        - figsize           (width, height) of plot in inches. (Default: (10,10))
        - ax                Pass a matplotlib axes object for further customization of the plot. (Default: None)
        - kegg_out          Path to file to save the highlighted KEGG pathway image, e.g. path/to/folder/kegg_pathway.png. (Default: None)
        - kegg_rank         Candidate pathway rank to be plotted in KEGG pathway image. (Default: 1)
        - json              If True, returns results in json format instead of data frame. (Default: False)
        - save              True/False whether to save the results in the local directory. (Default: False)
        - verbose           True/False whether to print progress information. (Default: True)
    
        Returns a data frame with the Enrichr results.
        """
    
        if species not in ["human", "mouse", "fly", "yeast", "worm", "fish"]:
            raise ValueError(
                f"Argument 'species' must be one of 'human', 'mouse', 'fly', 'yeast', 'worm', or 'fish'."
            )
    
        if species == "mouse":
            species = "human"
    
        species_enrichr = f"{species.capitalize()}Enrichr"
        if species == "human":
            species_enrichr = "Enrichr"
    
        if species != "human":
            if database in [
                "pathway",
                "transcription",
                "ontology",
                "diseases_drugs",
                "celltypes",
                "kinase_interactions",
            ]:
                raise ValueError(
                    f"Database '{database}' is not supported for species '{species}'."
                    f" Please select a database from the species-specific libraries listed at:"
                    f" https://maayanlab.cloud/{species_enrichr}/#stats."
                )
    
            if background:
                raise ValueError(
                    f"Background genes are only supported for species 'human' and 'mouse', not for species '{species}'."
                    f" Please set 'background=False' or leave it unspecified."
                )
    
            if background_list:
                raise ValueError(
                    f"Background genes are only supported for species 'human' and 'mouse', not for species '{species}'."
                    f" Please do not provide a value for 'background_list'."
                )
    
        # Define database
        # All available libraries: https://maayanlab.cloud/Enrichr/#libraries
        if species == "human":
            db_message = f"""
            Please note that there might be a more appropriate database for your application.
            Go to https://maayanlab.cloud/{species_enrichr}/#libraries for a full list of supported databases.
            """
        else:
            db_message = f"""
            Please note that there might be a more appropriate database for your application.
            Go to https://maayanlab.cloud/{species_enrichr}/#stats for a full list of supported databases.
            """
        if not isinstance(background, bool):
            raise ValueError(
                f"Argument`background` must be a boolean True/False. If you are adding a background list, use the argument `background_list` instead."
            )
    
        # Handle database shortcuts
        if database == "pathway":
            database = "KEGG_2021_Human"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        elif database == "transcription":
            database = "ChEA_2016"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        elif database == "ontology":
            database = "GO_Biological_Process_2021"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        elif database == "diseases_drugs":
            database = "GWAS_Catalog_2019"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        elif database == "celltypes":
            database = "PanglaoDB_Augmented_2021"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        elif database == "kinase_interactions":
            database = "KEA_2015"
            if verbose:
                logger.info(
                    f"Performing Enrichr analysis using database {database}. " + db_message
                )
    
        else:
            database = database
            if verbose:
                logger.info(f"Performing Enrichr analysis using database {database}.")
    
        # To generate a KEGG pathway image, confirm that the database is a KEGG database and pykegg is installed
        if kegg_out:
            if not database.startswith("KEGG"):
                logger.error(
                    "Please specify a KEGG database when generating a KEGG pathway image."
                )
                return
            try:
                import pykegg
            except ImportError:
                logger.error(
                    "Please install `pykegg` to generate a KEGG pathway image. Pykegg can be installed using pip: 'pip install pykegg'"
                )
                return
    
        # If single gene passed as string, convert to list
        if isinstance(genes, str):
            genes = [genes]
    
        ## Transform Ensembl IDs to gene symbols
        if ensembl:
            if verbose:
                logger.info("Getting gene symbols from Ensembl IDs.")
    
>           genes_v2 = ensembl_to_gene_names(genes)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^

gget/gget_enrichr.py:248: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ensembl_ids = ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']

    def ensembl_to_gene_names(ensembl_ids):
        """
        Function to fetch gene names from a list of Ensembl IDs using gget info.
        """
        genes_v2 = []
    
        # Remove version number if passed
        ensembl_ids = [gene_id.split(".")[0] for gene_id in ensembl_ids]
    
>       info_df = info(ensembl_ids, pdb=False, ncbi=False, uniprot=False, verbose=False)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

gget/gget_enrichr.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

ens_ids = ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']
wrap_text = False, ncbi = False, uniprot = False, pdb = False, json = False
verbose = False, save = False, expand = False, ensembl_only = False

    def info(
        ens_ids,
        wrap_text=False,
        ncbi=True,
        uniprot=True,
        pdb=False,
        json=False,
        verbose=True,
        save=False,
        expand=False,
        ensembl_only=False,
    ):
        """
        Fetch gene and transcript metadata using Ensembl IDs.
    
        Args:
        - ens_ids       One or more Ensembl IDs to look up (string or list of strings).
                        Also supports WormBase and Flybase IDs.
        - wrap_text     If True, displays data frame with wrapped text for easy reading. Default: False.
        - ncbi          If False, does not return data from NCBI. Default: True.
        - uniprot       If False, does not return data from UniProt. Default: True.
        - pdb           If True, also returns PDB IDs (might increase run time). Default: False.
        - json          If True, returns results in json/dictionary format instead of data frame. Default: False.
        - verbose       True/False whether to print progress information. Default True.
        - save          True/False wether to save csv with query results in current working directory. Default: False.
    
        Returns a data frame containing the requested information.
    
        Deprecated arguments:
        - expand        (gget info now always returns all of the available information)
        - ensembl_only  If True, only returns results from Ensembl (excludes PDB, UniProt, and NCBI results). Default: False.
        """
        # Handle deprecated arguments
        if expand:
            if verbose:
                logger.warning(
                    "'expand' argument deprecated! gget info now always returns all of the available information."
                )
        if ensembl_only:
            if verbose:
                logger.warning(
                    "'ensembl_only' argument deprecated! Please use arguments 'ncbi=False' and 'uniprot=False'."
                )
    
        # Set synonyms found by each database initially to none
        ncbi_synonyms = None
        df_uniprot = None
        df_pdb = pd.DataFrame()
        df_ncbi = pd.DataFrame()
    
        # Rename pdb, uniprot, ncbi arguments
        fetch_ncbi = ncbi
        fetch_uniprot = uniprot
        fetch_pdb = pdb
    
        # Define Ensembl REST API server
        server = ENSEMBL_REST_API
        # Define type of returned content from REST
        content_type = "application/json"
    
        ## Clean up Ensembl IDs
        # If single Ensembl ID passed as string, convert to list
        if type(ens_ids) == str:
            ens_ids = [ens_ids]
        # Remove Ensembl ID version if passed
        ens_ids_clean = []
        temp = 0
        for ensembl_ID in ens_ids:
            # But only for Ensembl ID (and not for flybase/wormbase IDs)
            if ensembl_ID.startswith("ENS"):
                ens_ids_clean.append(ensembl_ID.split(".")[0])
    
                if "." in ensembl_ID and temp == 0:
                    if verbose is True:
                        logger.info(
                            "We noticed that you passed a version number with your Ensembl ID.\n"
                            "Please note that gget info will always return information linked to the latest Ensembl ID version (see 'ensembl_id')."
                        )
                    temp = +1
    
            else:
                ens_ids_clean.append(ensembl_ID)
    
        # Remove duplicates in the Ensembl ID list without changing their order
        ens_ids_clean = sorted(set(ens_ids_clean), key=ens_ids_clean.index)
        # Create second clean list of Ensembl IDs which will not include IDs that were not found
        ens_ids_clean_2 = ens_ids_clean.copy()
    
        # Initiate dictionary to save results for all IDs in
        master_dict = {}
    
        # Query REST APIs from https://rest.ensembl.org/
        endpoint = "lookup/id/"
        query = {"ids": ens_ids_clean, "expand": True}
    
>       results_dict = post_query(server, endpoint, query)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

gget/gget_info.py:119: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

server = 'http://rest.ensembl.org/', endpoint = 'lookup/id/'
query = {'expand': True, 'ids': ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']}

    def post_query(server, endpoint, query):
        """
        Function to perform a POST API query.
    
        :param server:  Server to query .
        :param endpoint: Server endpoint
        :param query:   Query that is passed to server.
    
        :return: server output
        """
    
>       r = requests.post(
            server + endpoint, json=query, headers={"Content-Type": "application/json"}
        )

gget/utils.py:690: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

url = 'http://rest.ensembl.org/lookup/id/', data = None
json = {'expand': True, 'ids': ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']}
kwargs = {'headers': {'Content-Type': 'application/json'}}

    def post(url, data=None, json=None, **kwargs):
        r"""Sends a POST request.
    
        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
        """
    
>       return request("post", url, data=data, json=json, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/api.py:115: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

method = 'post', url = 'http://rest.ensembl.org/lookup/id/'
kwargs = {'data': None, 'headers': {'Content-Type': 'application/json'}, 'json': {'expand': True, 'ids': ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']}}
session = <requests.sessions.Session object at 0x7f6ae85b72f0>

    def request(method, url, **kwargs):
        """Constructs and sends a :class:`Request <Request>`.
    
        :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary, list of tuples or bytes to send
            in the query string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
        :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
            ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
            or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content_type'`` is a string
            defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
            to add for the file.
        :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send data
            before giving up, as a float, or a :ref:`(connect timeout, read
            timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
                the server's TLS certificate, or a string, in which case it must be a path
                to a CA bundle to use. Defaults to ``True``.
        :param stream: (optional) if ``False``, the response content will be immediately downloaded.
        :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
        :return: :class:`Response <Response>` object
        :rtype: requests.Response
    
        Usage::
    
          >>> import requests
          >>> req = requests.request('GET', 'https://httpbin.org/get')
          >>> req
          <Response [200]>
        """
    
        # By using the 'with' statement we are sure the session is closed, thus we
        # avoid leaving sockets open which can trigger a ResourceWarning in some
        # cases, and look like a memory leak in others.
        with sessions.Session() as session:
>           return session.request(method=method, url=url, **kwargs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/api.py:59: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f6ae85b72f0>, method = 'post'
url = 'http://rest.ensembl.org/lookup/id/', params = None, data = None
headers = {'Content-Type': 'application/json'}, cookies = None, files = None
auth = None, timeout = None, allow_redirects = True, proxies = {}, hooks = None
stream = None, verify = None, cert = None
json = {'expand': True, 'ids': ['ENSG00000106443', 'ENSG00000102317', 'ENSG00000188895', 'ENSG00000135365']}

    def request(
        self,
        method,
        url,
        params=None,
        data=None,
        headers=None,
        cookies=None,
        files=None,
        auth=None,
        timeout=None,
        allow_redirects=True,
        proxies=None,
        hooks=None,
        stream=None,
        verify=None,
        cert=None,
        json=None,
    ):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.
    
        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How many seconds to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param hooks: (optional) Dictionary mapping hook name to one event or
            list of events, event must be callable.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``. When set to
            ``False``, requests will accept any TLS certificate presented by
            the server, and will ignore hostname mismatches and/or expired
            certificates, which will make your application vulnerable to
            man-in-the-middle (MitM) attacks. Setting verify to ``False``
            may be useful during local development or testing.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)
    
        proxies = proxies or {}
    
        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )
    
        # Send the request.
        send_kwargs = {
            "timeout": timeout,
            "allow_redirects": allow_redirects,
        }
        send_kwargs.update(settings)
>       resp = self.send(prep, **send_kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/sessions.py:589: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.sessions.Session object at 0x7f6ae85b72f0>
request = <PreparedRequest [POST]>
kwargs = {'cert': None, 'proxies': OrderedDict(), 'stream': False, 'timeout': None, ...}
allow_redirects = True, stream = False, hooks = {'response': []}
adapter = <requests.adapters.HTTPAdapter object at 0x7f6ae85b71a0>
start = 1771519186.1576684

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.
    
        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault("stream", self.stream)
        kwargs.setdefault("verify", self.verify)
        kwargs.setdefault("cert", self.cert)
        if "proxies" not in kwargs:
            kwargs["proxies"] = resolve_proxies(request, self.proxies, self.trust_env)
    
        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError("You can only send PreparedRequests.")
    
        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop("allow_redirects", True)
        stream = kwargs.get("stream")
        hooks = request.hooks
    
        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)
    
        # Start time (approximately) of the request
        start = preferred_clock()
    
        # Send the request
>       r = adapter.send(request, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/sessions.py:703: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <requests.adapters.HTTPAdapter object at 0x7f6ae85b71a0>
request = <PreparedRequest [POST]>, stream = False
timeout = Timeout(connect=None, read=None, total=None), verify = True
cert = None, proxies = OrderedDict()

    def send(
        self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None
    ):
        """Sends PreparedRequest object. Returns Response object.
    
        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """
    
        try:
            conn = self.get_connection_with_tls_context(
                request, verify, proxies=proxies, cert=cert
            )
        except LocationValueError as e:
            raise InvalidURL(e, request=request)
    
        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(
            request,
            stream=stream,
            timeout=timeout,
            verify=verify,
            cert=cert,
            proxies=proxies,
        )
    
        chunked = not (request.body is None or "Content-Length" in request.headers)
    
        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError:
                raise ValueError(
                    f"Invalid timeout {timeout}. Pass a (connect, read) timeout tuple, "
                    f"or a single float to set both timeouts to the same value."
                )
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)
    
        try:
            resp = conn.urlopen(
                method=request.method,
                url=url,
                body=request.body,
                headers=request.headers,
                redirect=False,
                assert_same_host=False,
                preload_content=False,
                decode_content=False,
                retries=self.max_retries,
                timeout=timeout,
                chunked=chunked,
            )
    
        except (ProtocolError, OSError) as err:
>           raise ConnectionError(err, request=request)
E           requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))

/opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/requests/adapters.py:659: ConnectionError
------------------------------ Captured log call -------------------------------
INFO     gget.utils:gget_enrichr.py:194 Performing Enrichr analysis using database GO_Biological_Process_2021. 
        Please note that there might be a more appropriate database for your application. 
        Go to https://maayanlab.cloud/Enrichr/#libraries for a full list of supported databases.
        
INFO     gget.utils:gget_enrichr.py:246 Getting gene symbols from Ensembl IDs.
___________________ TestVirus.test_virus_with_length_filters ___________________

self = <tests.test_virus.TestVirus testMethod=test_virus_with_length_filters>

    @retry_on_network_error(max_retries=3, delay=5)
    def test_virus_with_length_filters(self):
        """Test that sequence length filters work correctly."""
        virus_name = "Zika virus"
        outfolder = self.test_output_dir
    
        result = virus(
            virus=virus_name,
            min_seq_length=10000,
            max_seq_length=11000,
            outfolder=outfolder
        )
    
        self.assertIsNone(result)
    
        files = self._check_output_files(virus_name, outfolder)
>       self.assertTrue(files["fasta"]["exists"], "FASTA file not created with length filters")
E       AssertionError: False is not true : FASTA file not created with length filters

tests/test_virus.py:504: AssertionError
------------------------------ Captured log call -------------------------------
INFO     gget.utils:gget_virus.py:4716 Starting virus data retrieval process...
INFO     gget.utils:gget_virus.py:4752 Query parameters: virus='Zika virus', is_accession=False, outfolder='test_virus_output'
INFO     gget.utils:gget_virus.py:4759 ============================================================
INFO     gget.utils:gget_virus.py:4760 STEP 1: VALIDATING INPUT ARGUMENTS AND OUTPUT DIRECTORY SETUP...
INFO     gget.utils:gget_virus.py:4761 ============================================================
INFO     gget.utils:gget_virus.py:4869 Input validation completed successfully
INFO     gget.utils:gget_virus.py:4881 Using specified output folder: test_virus_output
INFO     gget.utils:gget_virus.py:4901 ============================================================
INFO     gget.utils:gget_virus.py:4902 STEP 2: CHECKING FOR SARS-CoV-2 AND INFLUENZA A QUERIES TO APPLY OPTIMIZED CACHED PATHWAY
INFO     gget.utils:gget_virus.py:4903 ============================================================
INFO     gget.utils:gget_virus.py:4947  Skipping this step. No SARS-CoV-2 query detected.
INFO     gget.utils:gget_virus.py:4987  Skipping this step. No Alphainfluenza query detected.
INFO     gget.utils:gget_virus.py:5014 ============================================================
INFO     gget.utils:gget_virus.py:5015 STEP 3: Fetching virus metadata from NCBI API
INFO     gget.utils:gget_virus.py:5016 ============================================================
INFO     gget.utils:gget_virus.py:946 Streaming API metadata to temporary file: test_virus_output/tmp_20260219_162256_52f5b9/gget_metadata_20260219_162256_52f5b9.jsonl
ERROR    gget.utils:gget_virus.py:1285 ================================================================================
ERROR    gget.utils:gget_virus.py:1286  REQUEST FAILED
ERROR    gget.utils:gget_virus.py:1287 ================================================================================
ERROR    gget.utils:gget_virus.py:1288  Failed to fetch virus metadata: HTTPSConnectionPool(host='api.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=30)
ERROR    gget.utils:gget_virus.py:1289 ================================================================================
ERROR    gget.utils:gget_virus.py:5084 Failed to fetch virus metadata from NCBI API
INFO     gget.utils:gget_virus.py:3246 ============================================================
INFO     gget.utils:gget_virus.py:3247  Command summary saved: test_virus_output/command_summary.txt
INFO     gget.utils:gget_virus.py:5637 NCBI virus data retrieval process completed.
=============================== warnings summary ===============================
tests/test_blast.py::TestBlast::test_blast_nt
  /home/runner/work/gget/gget/gget/gget_blast.py:327: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.
    results_df = pd.read_html(str(dsc_table))[0]

tests/test_cbio.py::TestCbioSearch::test_cbio_search
tests/test_cbio.py::TestCbioSearch::test_cbio_search
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/swagger_spec_validator/validator12.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.
    from jsonschema import RefResolver

tests/test_cbio.py::TestCbioSearch::test_cbio_search
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/swagger_spec_validator/ref_validators.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.
    from jsonschema.validators import RefResolver

tests/test_cbio.py::TestCbioSearch::test_cbio_search
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/swagger_spec_validator/validator20.py:18: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.
    from jsonschema.validators import RefResolver

tests/test_cbio.py::TestCbioSearch::test_cbio_search
tests/test_cbio.py::TestCbioSearch::test_cbio_search
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/bravado_core/swagger20_validator.py:6: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.
    from jsonschema import RefResolver

tests/test_cbio.py::TestCbioSearch::test_cbio_search
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/bravado_core/spec.py:14: DeprecationWarning: jsonschema.RefResolver is deprecated as of v4.18.0, in favor of the https://github.com/python-jsonschema/referencing library, which provides more compliant referencing behavior as well as more flexible APIs for customization. A future release will remove RefResolver. Please file a feature request (on referencing) if you are missing an API for the kind of customization you need.
    from jsonschema.validators import RefResolver

tests/test_cbio.py: 16 warnings
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/site-packages/bravado_core/model.py:888: DeprecationWarning: jsonschema.RefResolver.in_scope is deprecated and will be removed in a future release.
    with spec.resolver.in_scope(additional_uri):

tests/test_cellxgene.py::TestCellxgene::test_cellxgene_adata
  /home/runner/work/gget/gget/gget/gget_cellxgene.py:222: FutureWarning: The argument `column_names` is deprecated and will be removed in a future release. Please use `obs_column_names` and `var_column_names` instead.
    adata = cellxgene_census.get_anndata(

tests/test_cellxgene.py::TestCellxgene::test_cellxgene_adata
tests/test_cellxgene.py::TestCellxgene::test_cellxgene_adata
  /opt/hostedtoolcache/Python/3.12.12/x64/lib/python3.12/functools.py:912: ImplicitModificationWarning: Transforming to str index.
    return dispatch(args[0].__class__)(*args, **kw)

tests/test_cosmic.py::TestCosmicWorkflow::test_cosmic_defaults
  /home/runner/work/gget/gget/gget/gget_cosmic.py:183: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.
    tar.extractall(path=tar_folder_path)

tests/test_cosmic.py::TestCosmicWorkflow::test_cosmic_defaults
  /home/runner/work/gget/gget/tests/from_json.py:69: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`
    expected_result = expected_result.replace({None: np.nan})

tests/test_mutate.py: 29 warnings
  /home/runner/work/gget/gget/gget/gget_mutate.py:663: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.
    mask = mutations[mut_column].str.contains(combined_pattern)

tests/test_ref.py: 22 warnings
tests/test_utils.py: 1 warning
  /home/runner/work/gget/gget/gget/utils.py:924: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    for subsoup in soup.body.findAll("a"):

tests/test_ref.py: 39 warnings
  /home/runner/work/gget/gget/gget/gget_ref.py:43: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    links = [stuff.text.strip() for stuff in soup.findAll("td")]

tests/test_ref.py::TestRef::test_ref
tests/test_ref.py::TestRef::test_ref_ftp
  /home/runner/work/gget/gget/gget/gget_ref.py:350: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    links = [stuff.text.strip() for stuff in soup.findAll("td")]

tests/test_ref.py: 32 warnings
tests/test_utils.py: 4 warnings
  /home/runner/work/gget/gget/gget/utils.py:899: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    for subsoup in soup.body.findAll("a"):

tests/test_ref.py: 7 warnings
tests/test_search.py: 44 warnings
  /home/runner/work/gget/gget/gget/utils.py:845: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    for subsoup in soup.body.findAll("a"):

tests/test_search.py: 10 warnings
  /home/runner/work/gget/gget/gget/gget_search.py:244: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
    df_temp = pd.read_sql(query, con=db_connection)

tests/test_search.py: 9 warnings
tests/test_utils.py: 1 warning
  /home/runner/work/gget/gget/gget/utils.py:822: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    for subsoup in soup.body.findAll("a"):

tests/test_search.py: 36 warnings
tests/test_utils.py: 4 warnings
  /home/runner/work/gget/gget/gget/utils.py:804: DeprecationWarning: Call to deprecated method findAll. (Replaced by find_all) -- Deprecated since version 4.0.0.
    for subsoup in soup.body.findAll("a"):

tests/test_search.py::TestSearch::test_search_gene_two_sw_limit
tests/test_search.py::TestSearch::test_search_transcript_one_sw
tests/test_search.py::TestSearch::test_search_transcript_two_sw_and
tests/test_search.py::TestSearch::test_search_transcript_two_sw_or
  /home/runner/work/gget/gget/gget/gget_search.py:279: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.
    df_temp = pd.read_sql(query, con=db_connection)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.12-final-0 _______________

Name                       Stmts   Miss  Cover   Missing
--------------------------------------------------------
gget/__init__.py              35      2    94%   34-35
gget/__main__.py               2      2     0%   1-3
gget/compile.py               39     27    31%   30-84
gget/constants.py             34      0   100%
gget/gget_8cube.py            83     28    66%   26-27, 34-43, 93, 105, 112, 115-118, 158, 175, 182, 185-188, 229, 246, 255, 258-261
gget/gget_alphafold.py       362    321    11%   86-108, 115-116, 123-149, 181-186, 233-867
gget/gget_archs4.py           79     13    84%   75-78, 84, 107, 123-126, 139-142, 148, 170, 198-201, 207
gget/gget_bgee.py             56      6    89%   60, 83, 103, 130, 154, 175
gget/gget_blast.py           127     36    72%   92, 124-142, 163-165, 204, 207, 246-248, 296-299, 302-303, 322-325, 332-333, 336-341, 346, 351-354
gget/gget_blat.py             86     10    88%   58-62, 95, 136, 139, 168, 232-233, 239
gget/gget_cbio.py            524    403    23%   28, 39-67, 77-87, 136-137, 143-147, 154-157, 161, 164, 172-177, 208, 226, 265, 271-275, 278, 282-294, 296, 322-331, 334, 376-389, 393-416, 420-441, 447-450, 454-473, 477, 494-537, 540-757, 760-789, 802-1164, 1218-1254
gget/gget_cellxgene.py        53      9    83%   21-22, 140-149, 176, 215, 231, 247
gget/gget_cosmic.py          277    153    45%   24-26, 30-82, 94-109, 112-114, 117-119, 122-126, 131-135, 140-142, 155-168, 189-202, 220, 242-243, 283-308, 311, 396-398, 410, 416, 424, 427-429, 454-472, 496-621, 637-646, 649, 651, 653, 852-855, 868-870, 879-891, 896-901
gget/gget_diamond.py          98     26    73%   16, 69, 75, 77, 95, 98-99, 105, 111, 117-121, 130-132, 145, 147, 160, 162, 181, 184, 216-217, 223
gget/gget_elm.py             158     22    86%   128, 278, 301, 325-332, 353, 420-423, 426, 436, 490, 503, 506-515, 519-520
gget/gget_enrichr.py         213     42    80%   39-42, 48, 172, 226-237, 254-255, 263-264, 290, 310, 316-322, 336, 364-374, 403-418, 439, 451-453, 555, 564-565, 575-576, 583
gget/gget_gpt.py              20      6    70%   56-65, 88, 110-111
gget/gget_info.py            316    106    66%   58-59, 63-64, 150-152, 161-162, 175, 201-206, 213-216, 242, 255-266, 300-308, 324-342, 368-369, 453-454, 461-462, 465-466, 469-470, 473-474, 507-508, 511-512, 515-516, 543-544, 547-548, 551-552, 575-576, 579-673, 677
gget/gget_muscle.py           85     12    86%   17, 45, 68-69, 78-80, 91, 94, 115, 162-163
gget/gget_mutate.py          434    193    56%   124-175, 186, 190-198, 215-226, 274-278, 283-287, 291-296, 300-305, 309-312, 317-320, 324-334, 340-350, 493, 516-520, 528, 538-542, 553-557, 576, 583, 593-600, 611, 616, 624, 635, 730-741, 855-879, 891-904, 948-985, 1032-1050, 1053-1056, 1070-1077, 1083-1093, 1109-1110, 1147, 1152, 1156, 1160, 1165-1241, 1255-1258, 1299, 1308-1324, 1332-1336, 1341, 1349, 1353
gget/gget_opentargets.py     148      6    96%   75, 184, 192-195, 204-205
gget/gget_pdb.py              60     22    63%   52, 58, 67, 75, 83, 104, 108-110, 113-129, 141-147
gget/gget_ref.py             215     57    73%   32, 97-98, 117-118, 124-152, 161, 174, 176, 178-179, 186-187, 225, 244, 256-258, 279-281, 308-310, 329-331, 384-386, 485-494, 507, 512-513, 529-534, 538, 542, 548, 553-554
gget/gget_search.py          142     23    84%   84-87, 96, 113, 117, 125, 149-150, 157, 165-171, 213-222, 308-309, 315-316, 368-369, 376-377, 385
gget/gget_seq.py             146     24    84%   44-47, 49, 119, 140-143, 177-178, 207-208, 245-248, 271-272, 293, 312-315, 334, 356, 365, 402-405
gget/gget_setup.py           215    149    31%   49-90, 108, 113, 116, 128-138, 152, 175-176, 189, 199, 209, 221-466
gget/gget_virus.py          2409   1174    51%   131, 192, 234, 237, 255, 259, 270-271, 312-316, 321-335, 342, 353-354, 372-377, 414-453, 506, 630-631, 635, 685-686, 696, 698, 700, 702, 704, 706, 728, 740-745, 755-756, 795-826, 947-949, 1009-1010, 1035-1037, 1049-1104, 1108-1161, 1165-1259, 1265-1282, 1295-1296, 1307-1308, 1350-1430, 1455-1456, 1489-1490, 1523-1661, 1686-1726, 1776-1911, 1959-2071, 2125-2232, 2266, 2273-2274, 2342, 2361-2383, 2399-2401, 2447, 2478, 2501, 2510-2564, 2572, 2575-2576, 2583-2585, 2596-2610, 2677-2678, 2716-2723, 2730, 2768, 2774-2780, 2808-2814, 2826-2832, 2863, 2877-2878, 3026-3027, 3070, 3073-3074, 3076-3078, 3114, 3117-3118, 3120-3122, 3134-3135, 3146-3154, 3160-3162, 3172-3175, 3182, 3187-3203, 3207-3220, 3224-3232, 3250-3253, 3272-3273, 3327-3330, 3492-3494, 3524-3526, 3559, 3562, 3574-3575, 3604-3605, 3609-3617, 3621-3638, 3648, 3651, 3655-3659, 3702-3704, 3735, 3745-3810, 3905, 3942-3948, 3958, 3987-3990, 4017-4020, 4030, 4033-4034, 4099, 4142, 4154-4157, 4318-4320, 4386, 4419-4421, 4435-4449, 4453-4463, 4467-4471, 4476-4478, 4484-4488, 4492-4505, 4532-4550, 4554-4573, 4585-4588, 4591-4594, 4607-4614, 4746-4750, 4821, 4877-4879, 4912-4945, 4953-4985, 4995-5011, 5064-5065, 5100-5115, 5132-5133, 5176-5192, 5203-5204, 5213-5232, 5237, 5280, 5293-5295, 5304-5309, 5338-5352, 5375-5384, 5417-5420, 5439-5585, 5600-5601, 5606-5617, 5619, 5622-5625, 5628-5632, 5642
gget/main.py                 837    837     0%   1-3773
gget/utils.py                448     77    83%   31, 36-42, 72, 95, 119, 122, 186, 193, 245, 257, 285, 296, 347, 367, 378, 411-412, 452-453, 468-469, 476-478, 494-495, 501-502, 623-639, 676, 695, 757, 797, 837, 953, 961, 969-989, 994, 999, 1005-1006, 1024-1025, 1116, 1140-1141, 1156, 1164
--------------------------------------------------------
TOTAL                       7701   3786    51%
============================= slowest 10 durations =============================
459.24s call     tests/test_enrichr.py::TestEnrichr::test_enrichr_background_ensembl
344.32s call     tests/test_info.py::TestInfo::test_info_exon
282.44s call     tests/test_enrichr.py::TestEnrichr::test_enrichr_ensembl_ids
261.27s call     tests/test_info.py::TestInfo::test_info_gene
242.16s call     tests/test_info.py::TestInfo::test_info_mix
239.02s call     tests/test_blast.py::TestBlast::test_blast_nt
236.77s call     tests/test_info.py::TestInfo::test_info_transcript
235.27s call     tests/test_info.py::TestInfo::test_info_WB_transcript
163.02s call     tests/test_archs4.py::TestArchs4::test_archs4_tissue_ensembl
148.20s call     tests/test_info.py::TestInfo::test_info_gene_list_non_model
=========================== short test summary info ============================
FAILED tests/test_enrichr.py::TestEnrichr::test_enrichr_ensembl_ids - requests.exceptions.ConnectionError: ('Connection aborted.', ConnectionResetError(104, 'Connection reset by peer'))
FAILED tests/test_virus.py::TestVirus::test_virus_with_length_filters - AssertionError: False is not true : FASTA file not created with length filters
=========== 2 failed, 262 passed, 273 warnings in 4257.89s (1:10:57) ===========
